# Creating row summary statistics for the sample
snpsummary.row <- row.summary(genotype.s)
# Calculating the inbreeding coefficient for the sample and adding it to the
# row summary statistics for the sample
MAF <- snpsummary.col$MAF
callmatrix <- !is.na(genotype.s)
hetExp <- callmatrix %*% (2*MAF*(1-MAF))
hetObs <- with(snpsummary.row, Heterozygosity*(ncol(genotype.s))*Call.rate)
snpsummary.row$hetF <- 1-(hetObs/hetExp)
# Setting thresholds for sample filtering
samp.call <- 0.95       # 95% call rate
het.cutoff <- 0.10      # Inbreeding coefficient cutoff
# Filtering sample based on call rate and heterozygosity
fil.sample <- with(snpsummary.row, !is.na(Call.rate) & Call.rate > samp.call &
abs(hetF) <= het.cutoff)
fil.sample[is.na(fil.sample)] <- FALSE   #removing NAs from the sample
print(nrow(genotype.s)-sum(fil.sample))  # 0 subjects removed
# Subset genotype and phenotype data for subjects meeting the heterozygosity and
# call rate criteria.
genotype.s <- genotype.s[fil.sample,]
phenotype <- phenotype[rownames(genotype.s),]
head(genotype.s)
# === 3) Sample level-filtering: Relatedness  ==================================
# Now we will further filter the sample for relatedness.
# We will use the linkage disequilibrium as a threshold to remove redundancy.
# We will use the kinship threshold to remove related individuals from the
# sample pool.
# Setting thresholds for kinship and LD
kin.cutoff <- 0.1  # Kinship Cut-Off based on IBD coefficient
ld.cutoff <- 0.2   # LD cut-off. 0.2 seems to be the standard in GWAS.
# Creating gds which are a combination of the PLINK files
# SNPRelate functions require gds files to run
# Converting from PLINK to GDS
snpgdsBED2GDS(gwas.data$bed, gwas.data$fam, gwas.data$bim, gwas.data$gds)
genofile <- snpgdsOpen(gwas.data$gds, readonly = FALSE)
# Removing automatically added "-1" suffixes
gds.ids <- read.gdsn(index.gdsn(genofile, "sample.id"))
gds.ids <- sub("-1", "", gds.ids)
add.gdsn(genofile, "sample.id", gds.ids, replace = TRUE)
# Prune SNPs for IBD analysis
set.seed(1000)
genosample.ids <- rownames(genotype.s)
snpSUB <- snpgdsLDpruning(genofile, ld.threshold = ld.cutoff,
sample.id = genosample.ids,
snp.id = colnames(genotype.s))
snpset.ibd <- unlist(snpSUB, use.names = FALSE)
cat(length(snpset.ibd), "will be used in IBD analysis\n") # expect 72890 SNP's
# Find IBD coefficients using Method of Moments procedure.
# Method of Moments is a method of estimating population parameters
# include pairwise kinship.
ibd <- snpgdsIBDMoM(genofile, kinship = TRUE,
sample.id = genosample.ids,
snp.id = snpset.ibd,
num.thread = 1)
ibdcoeff <- snpgdsIBDSelection(ibd) # Pairwise sample comparison
head(ibdcoeff)
# check if there are any candidates for relatedness
ibdcoeff <- ibdcoeff [ibdcoeff$kinship >= kin.cutoff, ]
# Iteratively remove samples with high kinship starting with the sample with
# the most pairings. The statistical significance of a GWAS analysis is
# impaired by a high degree of relatedness within the population. So, we want
# to eliminate kinship as much as we possibly can.
# create object for samples
related.samples <- NULL
# run iterative loop to add samples to related.samples from ibdcoeff
while (nrow(ibdcoeff) > 0 ) {
# Count the number of occurrences of each and take the top one
sample.counts <- arrange(count(c(ibdcoeff$ID1, ibdcoeff$ID2)), -freq)
rm.sample <- sample.counts[1, "x"]
cat("Removing sample", as.character(rm.sample), "too closely related to",
sample.counts[1, "freq"], "other samples. \n")
# Remove from ibdcoeff and add to list
ibdcoeff <- ibdcoeff[ibdcoeff$ID1 !=rm.sample & ibdcoeff$ID2 != rm.sample,]
related.samples <- c(as.character(rm.sample), related.samples)
}
# Subset genotype and phenotype to include only unrelated samples
genotype.s <- genotype.s[!(rownames(genotype.s) %in% related.samples),]
phenotype <- phenotype[!(phenotype$FamID %in% related.samples),]
genosample.ids <- rownames(genotype.s)
cat(length(related.samples), "similar samples removed due to
correlation coefficient >=", kin.cutoff, "\n")
print(genotype.s) # except all 1401 subject remain
# Find PCA matrix
pca.anc <- snpgdsPCA(genofile, sample.id = genosample.ids, snp.id = snpset.ibd,
num.thread = 1)
# Create data frame of first two principal components
pctab <- data.frame(sample.id = pca.anc$sample.id,
PC1 = pca.anc$eigenvect[,1], # the first eigenvector
PC2 = pca.anc$eigenvect[,2], # the second eigenvector
stringsAsFactors = FALSE)
# Plot the first two principal components
# Save plot as pdf in graphics folder
pdf(paste(p.graphics, "pc.plot.pdf", sep = ""))
pc.plot <- plot(pctab$PC2, pctab$PC1, xlab = "Principal Component 2",
ylab = "Principal Component 1", main = "Ancestry Plot")
dev.off()
?dev.off()
# Setting threshold for HWE test p < 1x10^10-6
HWE.thres <- 10^-6
# Filter based on population controls, in this case individuals without
# coronary artery disease(CAD).
CADcontrols <- phenotype[phenotype$CAD==0, 'FamID' ]
snpsum.col.cont <- col.summary(genotype.s[CADcontrols,])
# Filter based on HWE
HWE.use <- with(snpsum.col.cont,
!is.na(z.HWE) & ( abs(z.HWE) < abs( qnorm(HWE.thres/2))))
HWE.use[is.na(HWE.use)] <- FALSE          # Remove NA's as well
cat(ncol(genotype.s)-sum(HWE.use),"SNPs will be removed due to high HWE.\n")
# Subset genotype and SNP summary data for SNPs that pass HWE criteria
genotype.s <- genotype.s[,HWE.use]
print(head(genotype.s))
# Write genotype.s, genoBim & phenotype for future use
# *Note this function can take a few minutes
save(genotype.s, geno.bim, phenotype, file = working.data.fname(2))
# Load data created in previous script, 3.Data.filtering.R
load(working.data.fname(2))
# Write genotype.s, genoBim, genofile & phenotype for future use
# *Note this function can take a few minutes
save(genotype.s, geno.bim, genofile, phenotype, file = working.data.fname(2))
load(working.data.fname(2))
# The following script generates principle components needed for genome-wide
# association analyses along with imputed SNPs which are usefull for association
# identification. The imputed SNPs will be visualized on the Manhattan plot.
# 1) Principal Component Generation
# 2) Sample level-filtering: Call Rate and Heterozygosity
# 3) Sample level-filtering: Relatedness
# 4) Sample level-filtering: Ancestry
# 5) SNP level-filtering: Hardy-Weinberg equilibrium
# === 1) Principal Component Generation ========================================
# Principal Components (PCs) based on observed genotype data capture
# information on substructure - genetic diversity in an apparently homogenous
# population that is caused by population genetic history (migration,
# selection, and/or ethnic integration). These substructures cannot be inferred
# from self-reported race and ethnicity variables.
# Generating principal components for modeling
# set LD threshold to 0.2
ld.cutoff <- 0.2
# Set seed for reproducibility
set.seed(1000)
# Create vector of sample ids from genomic data
genosample.ids <- rownames(genotype.s)
# Prune SNPs
snpSUB <- snpgdsLDpruning(genofile, ld.threshold = ld.cutoff,
sample.id = genosample.ids,
snp.id = colnames(genotype.s))
snpset.pca <- unlist(snpSUB, use.names = FALSE)
cat(length(snpset.pca), "\n") #72665 SNPs will be used in PCA analysis
# Generate principle components from SNPs within LD threshold
pca <- snpgdsPCA(genofile, sample.id = genosample.ids,
snp.id = snpset.pca, num.thread = 1)
# Find and record first 10 principal components
# pcs will be a N:10 matrix. Each column is a principal component.
pcs <- data.frame(FAMID = pca$sample.id, pca$eigenvect[,1:10],
stringsAsFactors = FALSE)
colnames(pcs)[2:11] <- paste("pc", 1:10, sep ="")
# Rename "FAMID" to "FamID" to match other files
names(pcs)[names(pcs) == "FAMID"] <- "FamID"
print(head(pcs))
# === 2) Imputation of non-typed SNPs ==========================================
# Genotypes of untyped SNPs may have a functional relationship to the
# outcome and therefore provide additional power for identifying association.
# Imputation of SNPs involve estimating missing genotypes from the haplotype
# or genotype reference panel. Here, we use the 1000 Genomes data for this.
# Read in 1000g data for given chromosome 16
thougeno <- read.pedfile(onethou.fn$ped, snps = onethou.fn$info, which = 1)
# Obtain genotype data for given chromosome
geno.matrix <- thougeno$genotypes
# Obtain the chromosome position for each SNP
support <- thougeno$map
colnames(support) <- c("SNP", "position", "N1", "N2")
head(support)
# Imputation of non-typed 1000g SNPs
# Subset for SNPs on given chromosome
pres.SNPS <- colnames(genotype.s)
pres.dat.chr <- geno.bim[geno.bim$SNP %in% pres.SNPS & geno.bim$chr==16,]
target.SNPS <- pres.dat.chr$SNP
# Subset 1000g data for our SNPs
# "missing" and "present" are snpMatrix objects needed for imputation rules
is.present <- colnames(geno.matrix) %in% target.SNPS
missing <- geno.matrix[,!is.present]
print(missing)
present <- geno.matrix[, is.present]
print(present)
# Obtain positions of SNPs to be used for imputation rules
pos.present <- support$position[is.present]
pos.missing <- support$position[!is.present]
# Calculate and store the imputation rules using snp.imputation()
rules <- snp.imputation(present, missing, pos.present, pos.missing)
# Remove failed imputations
rules <- rules[can.impute(rules)]
cat("Imputation rules for", length(rules), "SNPs were estimated\n")
# Quality control for imputation certainty and MAF
# Set thresholds
r2threshold <- 0.7
minor <- 0.01
# Filter on imputation certainty and MAF
rules <- rules[imputation.r2(rules) >= r2threshold]
cat(length(rules),
"imputation rules remain after uncertain imputations were removed\n")
# 162628 imputation rules remain after uncertain imputation were removed
rules <- rules[imputation.maf(rules) >= minor]
cat(length(rules), "imputation rules remain after MAF filtering\n")
# Obtain posterior expectation of genotypes of imputed SNPs
target <- genotype.s[, target.SNPS]
imputed <- impute.snps(rules, target, as.numeric = FALSE)
print(imputed)
save(genotype.s, geno.bim, phenotype, file = working.data.fname(2))
# Write genotype.s, genoBim, genofile & phenotype for future use
# *Note this function can take a few minutes
save(genotype.s, geno.bim, genofile, phenotype, file = working.data.fname(3))
save(genotype.s, geno.bim, genofile, phenotype, pcs, support, imputed,
file = working.data.fname(4))
load(working.data.fname(4))
pheno.sub <- merge.data.frame(phenotype,pcs)
pheno.sub
# Rank-based inverse normal transformation of
pheno.sub$phenotype <- rntransform(pheno.sub$hdl, family = "gaussian")
# Show that the assumptions of normality met after transformation
par(mfrow=c(1,2))
hist(pheno.sub$hdl, main = "Histogram of HDL", xlab = "HDL")
hist(pheno.sub$phenotype, main = "Histogram of Transformed HDL",
xlab = "Transformed HDL")
# Remove columns that are unnecessary from the table
pheno.sub$hdl <- NULL
pheno.sub$ldl <- NULL
pheno.sub$tg <- NULL
pheno.sub$CAD <- NULL
pheno.sub
# Rename columns to match names necessary for GWAS() function
names(pheno.sub)[names(pheno.sub ) == "FamID"] <- "id"
# Include only subjects with HDL data
pheno.sub <- pheno.sub[!is.na(pheno.sub$phenotype),]
# 1309 subjects identified to have phenotype data
print (head(pheno.sub))
# Reading GWAA output
GWAS.output <- read.table(gwaa.out, sep = "",header=TRUE,
colClasses=c("character"))
head(GWAS.output)
# Calculating the -log10 of the p-values
GWAS.output$p.value <- as.numeric(GWAS.output$p.value)
GWAS.output$neg.logp <- -log10(GWAS.output$p.value)
head(GWAS.output)
# Merge output with geno.bim by SNP name to add position and chromosome number
GWAS.output <- merge(GWAS.output, geno.bim[,c("SNP", "chr", "position")],
by = "SNP")
head(GWAS.output)
# Order SNPs by significance
GWAS.output <- arrange(GWAS.output, neg.logp)
print(head(GWAS.output))
# === 4) Association analysis of imputed SNPs ==================================
# Association analysis of imputed SNPs to be included in Manhattan plot.
# Imputed SNPs will be compared to the same threshold as the typed SNPs
# Setting row names for pheno.sub
rownames(pheno.sub) <- pheno.sub$id
# Performing association testing for the imputed SNPs
imp <- snp.rhs.tests(phenotype ~ sex + age + pc1 + pc2 + pc3 + pc4 + pc5 + pc6 +
pc7 + pc8 + pc9 + pc10, family = "Gaussian",
data = pheno.sub, snp.data = target, rules = rules)
# Obtain p values for imputed SNPs
imp.results <- data.frame(SNP = imp@snp.names, p.value = p.value(imp),
stringsAsFactors = FALSE)
imp.results <- imp.results[!is.na(imp.results$p.value),]
# Merge imputation testing results with support
impute.out <- merge(imp.results, support[,c("SNP", "position")])
# Subsetting for chromosome 16 based on available 1000 Genomes data
impute.out$chr <- 16
# Tagging SNPs by type
impute.out$type <- "imputed"
# Calculating the -log10 of the imputed p-values
impute.out$neg.logp <- -log10(impute.out$p.value)
# Order by p-values
impute.out <- arrange(impute.out, p.value)
print(head(impute.out))
# map2gene function
# Returns the subset of SNPs that are within extended boundary of gene
# using the coords table of gene locations
map2gene <- function(gene, coords, SNPs, extend.boundary = 5000) {
coordsSub <- coords[coords$gene == gene,]
#Subset coordinate file for spcified gene
coordsSub$start <- coordsSub$start - extend.boundary # Extend gene boundaries
coordsSub$stop <- coordsSub$stop + extend.boundary
SNPsub <- SNPs[SNPs$position >= coordsSub$start
& SNPs$position <= coordsSub$stop &
SNPs$chr == coordsSub$chr,] #Subset for SNPs in gene
return(data.frame(SNPsub, gene = gene, stringsAsFactors = FALSE))
}
#Reading file containing protein coding gene coordinates
genes <- read.csv(protein.coding.coords.fname, stringsAsFactors = FALSE)
#Subset for CETP SNPs
impCETP <- map2gene("CETP", coords = genes, SNPs = impute.out)
# Filtering the imputed CETP SNP genotypes
impCETPgeno <- imputed[, impCETP$SNP]
# === 5) Integrating typed and imputed SNPs  ==================================
# Merging of typed and imputed SNPs for visualization in next script.
# Tagging SNPs by type
GWAS.output$type <- "typed"
#
GWAS.comb <- rbind.fill(GWAS.output, impute.out)
head(GWAS.comb)
tail(GWAS.comb)
str(GWAS.comb)
#Subset for CETP SNPs
typCETP <- map2gene("CETP", coords = genes, SNPs = GWAS.output)
#Combine CETP SNPs for typed and imputed analysis
CETP <- rbind.fill(typCETP, impCETP)[,c("SNP", "p.value", "neg.logp", "chr",
"position", "type", "gene")]
print(CETP)
# on to script 6.Visualization
#___ end _______________________________________________________________________
# Write genotype.s, genoBim, genofile & phenotype for future use
# *Note this function can take a few minutes
save(CETP, GWAS.output, GWAS.comb, file = working.data.fname(4))
# Write genotype.s, genoBim, genofile & phenotype for future use
# *Note this function can take a few minutes
save(CETP, GWAS.output, GWAS.comb, file = working.data.fname(5))
# ******************************************************************************
# Write genotype.s, genoBim, genofile & phenotype for future use
# *Note this function can take a few minutes
save(genotype.s, geno.bim, genofile, phenotype, pcs, support, imputed,
file = working.data.fname(4))
# Write GWAS.output & GWAS.comb for future use.
# *Note this function can take a few minutes
save(GWAS.output, GWAS.comb, file = working.data.fname(5))
# Tagging SNPs by type
GWAS.output$type <- "typed"
# Data check to make sure plots can run correctly.
GWAS.output$t.value <- as.numeric(GWAS.output$t.value)
# Write GWAS.output & GWAS.comb for future use.
# *Note this function can take a few minutes
save(GWAS.output, GWAS.comb, file = working.data.fname(5))
# Load data created in previous script, 3.Data.filtering.R
load(working.data.fname(5))
# === Visualization ============================================================
# *Note 1.Main. R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# Load data created in previous script, 5.Data.analysis.R
load(working.data.fname(5))
# Visualizing the results of the GWAS analysis.
# This script creates a Manhattan plot and a QQ plot from the analysed data.
# Plots are saved as pdfs to c.graphics folder.
# 1) Manhattan plot
# 2) Q-Q plot
# === 1) Manhattan plot ========================================================
# Manhattan plots are used to visualize GWA significance level by chromosome
# location. Visual inspection of this plot allows for identification of SNPs
# with relatively small p-values that are in regions with relatively large and
# non-significant p-values, suggesting potentially false findings. Association
# significance is established by p-values being above defined threshold such as
# the Bonferroni corrected threshold or the less stringent suggestive
# association threshold.
# we use a function created by Reed et. al (2015) to generate this plot.
# loading Manhattan Plot function
source("Manhattan.plot.R")
# creating Manhattan Plot and saving it as a .pdf
pdf(paste(p.graphics, "ManhattanPlot.pdf", sep = ""))
par(mfrow = c(1,1))
manhattan.plot.s <- GWAS.manhattan(GWAS.comb)
dev.off()
# === 2) Q-Q plot ===============================================================
# Q-Q plots are used to visualize the relationship between the expected
# and observed distributions of SNP-level test statistics. We use the function
# estlambda from the package GenABEL to generate our QQ plots.
# creating QQ Plot and saving it as a .pdf
pdf(paste(p.graphics, "lambda.plot.pdf", sep = ""))
lambda.plot.s <- estlambda(GWAS.output$t.value^2, plot = TRUE,
method = "median")
dev.off()
#___ end _______________________________________________________________________
# === GWAS tutorial ============================================================
# authors: Umayeer Milky, Severin Santana
# This code is an adaptation of the codes demonstrated by  Reed et al. (2015),
# Foulkes (2016), Lima (2017) & Marees et al.(2018).
# The code runs a genome-wide association study on genomic and phenotype data.
# The GWA results are visualized in a Manhattan plot sorted to look for
# correlations that cross a Bonferroni corrected threshold or a less stringent
# suggestive association threshold.
# The code is designed to run one GWA analysis at a time and
# should not be used to analyze data from multiple populations parallel.
# R version
R.version.string
# "R version 4.1.2 (2021-11-01)"
# NOTE: run the 1.Main.R before starting your session.
# === Notes ====================================================================
# • The code must be run sequentially, following the numerical order,
#   the .R script files without numerical names do not need to be run.
#   However the code saves objects between scripts such that the environment can
#   be closed or restartet if needed or if a crash happens.
# • Ensure all the packages listed below are installed and loaded before
#   running the code.
# • After running the main code please continue to the
#   "Test" & "Simulated Data" folders to run the code with a independently
#   downloaded data set and a simulated data set, respectively.
# • After running 3.2.Data.simulation.R, the simulated data files simulated.bed,
#   simulated.bim, simulated.fam need to be manually moved from the
#   "Simulated Data" folder to "a.simulated.data"
# === Script index =============================================================
# 1.Main.R
# 2.Reading.raw.data.R
# 3.Data.filtering.R
# 4.Dataa.generation.R
# 5.Data.analysis.R
# 6.Visualization.R
# For "Test" folder
# 2.1.Main.R
# 2.2.Reading.raw.data.R
# 2.3.Data.filtering.R
# 2.4.Dataa.generation.R
# 2.5.Data.analysis.R
# 2.6.Visualization.R
# For "Simulated Data" folder
# 2.1.Main.R
# 2.2.Data.simulation.R
# 2.3.Reading.raw.data.R
# 2.4.Data.filtering.R
# 2.5.Dataa.generation.R
# 2.6.Data.analysis.R
# 2.7.Visualization.R
# Other scripts included in this repository are required to run some functions
# used in the aforementioned scripts.
# === Installing Packages ======================================================
# The following packages are required to run the code
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("snpStats")
BiocManager::install("SNPRelate")
BiocManager::install("rtracklayer")
BiocManager::install("biomaRt")
install.packages(c("plyr", "LDheatmap", "doParallel", "ggplot2"))
install.packages(c("GenABEL.data_1.0.0.tar.gz", "GenABEL_1.8-0.tar.gz"),
repos = NULL, type="source")
library("snpStats")
library("SNPRelate")
library("biomaRt")
library("plyr")
library("GenABEL")
library("LDheatmap")
library("doParallel")
library("ggplot2")
library("survival")
library("rtracklayer")
# === Customizing data directory ===============================================
main.dir <- getwd()
# === Folder management ========================================================
folder.names <- c("a.raw.data", "b.working.data", "c.GWAS", "d.graphics")
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
# ******************************************************************************
# Creation of paths to each folder in repository
p.data.raw <- paste(main.dir, "/", folder.names[1], "/", sep = "")
p.work.data <- paste(main.dir, "/", folder.names[2], "/", sep = "")
p.gwas <- paste(main.dir, "/", folder.names[3], "/", sep = "")
p.graphics <- paste(main.dir, "/", folder.names[4], "/", sep = "")
# === Input Files ==============================================================
# Create character objects that are a formatted combination of input values
gwas.data <- lapply(c(bed="bed", bim="bim", fam="fam", gds="gds"),
function(n) sprintf("%s/GWAStutorial.%s",
p.data.raw, n))
clinical.data <- sprintf("%s/GWAStutorial_clinical.csv", p.data.raw)
onethou.fn <- lapply(c(info='info',ped='ped'),
function(n) sprintf("%s/chr16_1000g_CEU.%s",
p.data.raw, n))
protein.coding.coords.fname <- sprintf("%s/ProCodgene_coords.csv", p.data.raw)
# === Output Files =============================================================
gwaa.out <- sprintf("%s/GWASout.txt", p.gwas)
impute.out.fname <- sprintf("%s/Imputation.csv", p.gwas)
# Working data saved between each script so each script can run independently.
# Use save(data, file=working.data.fname(num)) to save data between scripts.
working.data.fname <- function(num) { sprintf("%s/working.%s.Rdata",
p.work.data, num) }
# on to script 2.Reading.raw.data.R
#___ end _______________________________________________________________________
# === Visualization ============================================================
# *Note 1.Main. R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# Load data created in previous script, 5.Data.analysis.R
load(working.data.fname(5))
# Visualizing the results of the GWAS analysis.
# This script creates a Manhattan plot and a QQ plot from the analysed data.
# Plots are saved as pdfs to c.graphics folder.
# 1) Manhattan plot
# 2) Q-Q plot
# === 1) Manhattan plot ========================================================
# Manhattan plots are used to visualize GWA significance level by chromosome
# location. Visual inspection of this plot allows for identification of SNPs
# with relatively small p-values that are in regions with relatively large and
# non-significant p-values, suggesting potentially false findings. Association
# significance is established by p-values being above defined threshold such as
# the Bonferroni corrected threshold or the less stringent suggestive
# association threshold.
# we use a function created by Reed et. al (2015) to generate this plot.
# loading Manhattan Plot function
source("Manhattan.plot.R")
# creating Manhattan Plot and saving it as a .pdf
pdf(paste(p.graphics, "ManhattanPlot.pdf", sep = ""))
par(mfrow = c(1,1))
manhattan.plot.s <- GWAS.manhattan(GWAS.comb)
dev.off()
# === 2) Q-Q plot ===============================================================
# Q-Q plots are used to visualize the relationship between the expected
# and observed distributions of SNP-level test statistics. We use the function
# estlambda from the package GenABEL to generate our QQ plots.
# creating QQ Plot and saving it as a .pdf
pdf(paste(p.graphics, "lambda.plot.pdf", sep = ""))
lambda.plot.s <- estlambda(GWAS.output$t.value^2, plot = TRUE,
method = "median")
dev.off()
#___ end _______________________________________________________________________
