# Merge imputation testing results with support
impute.out <- merge(imp.results, support[,c("SNP", "position")])
impute.out$chr <- 16
impute.out$type <- "imputed"
# Calculating the -log10 of the imputed p-values
impute.out$neg.logp <- -log10(impute.out$p.value)
# Order by p-values
impute.out <- arrange(impute.out, p.value)
print(head(impute.out))
source("map2gene.R")
#Reading file containing protein coding gene coordinates
genes <- read.csv(protein.coding.coords.fname, stringsAsFactors = FALSE)
#Subset for CETP SNPs
impCETP <- map2gene("CETP", coords = genes, SNPs = impute.out)
# Filtering the imputed CETP SNP genotypes
impCETPgeno <- imputed[, impCETP$SNP]
## Integrating typed and imputed SNPs
GWAS.output$type <- "typed"
GWAS.comb <- rbind.fill(GWAS.output, impute.out)
head(GWAS.comb)
tail(GWAS.comb)
str(GWAS.comb)
#Subset for CETP SNPs
typCETP <- map2gene("CETP", coords = genes, SNPs = GWAS.output)
#Combine CETP SNPs for typed and imputed analysis
CETP <- rbind.fill(typCETP, impCETP)[,c("SNP", "p.value", "neg.logp", "chr",
"position", "type", "gene")]
print(CETP)
gc()
# on to script 6.Visualization
# ---- manhattan ----
# Receives a data.frame of SNPs with neg.logp, chr, position, and type.
# Plots Manhattan plot with significant SNPs highlighted.
GWAS.manhattan <- function(GWAS, col.snps=c("black","gray"),
col.detected=c("blue"), col.imputed=c("red"), col.text="black",
title="GWAS Tutorial Manhattan Plot", display.text=TRUE,
bonferroni.alpha=0.05, bonferroni.adjustment=1000000,
Lstringent.adjustment=10000) {
bonferroni.thresh <- -log10(bonferroni.alpha / bonferroni.adjustment)
Lstringent.thresh <- -log10(bonferroni.alpha / Lstringent.adjustment)
xscale <- 10000000
manhat <- GWAS[!grepl("[A-z]",GWAS$chr),]
#sort the data by chromosome and then location
manhat.ord <- manhat[order(as.numeric(manhat$chr),manhat$position),]
manhat.ord <- manhat.ord[!is.na(manhat.ord$position),]
##Finding the maximum position for each chromosome
max.pos <- sapply(1:21, function(i) { max(manhat.ord$position[manhat.ord$chr==i],0) })
max.pos2 <- c(0, cumsum(max.pos))
#Add spacing between chromosomes
max.pos2 <- max.pos2 + c(0:21) * xscale * 10
#defining the positions of each snp in the plot
manhat.ord$pos <- manhat.ord$position + max.pos2[as.numeric(manhat.ord$chr)]
# alternate coloring of chromosomes
manhat.ord$col <- col.snps[1 + as.numeric(manhat.ord$chr) %% 2]
# draw the chromosome label roughly in the middle of each chromosome band
text.pos <- sapply(c(1:22), function(i) { mean(manhat.ord$pos[manhat.ord$chr==i]) })
# Plot the data
plot(manhat.ord$pos[manhat.ord$type=="typed"]/xscale, manhat.ord$neg.logp[manhat.ord$type=="typed"],
pch=20, cex=.3, col= manhat.ord$col[manhat.ord$type=="typed"], xlab="Chromosome",
ylab="Negative Log P-Value", axes=F, ylim=c(0,max(manhat$neg.logp)+1))
points(manhat.ord$pos[manhat.ord$type=="imputed"]/xscale, manhat.ord$neg.logp[manhat.ord$type=="imputed"],
pch=20, cex=.4, col = col.imputed)
points(manhat.ord$pos[manhat.ord$type=="typed"]/xscale, manhat.ord$neg.logp[manhat.ord$type=="typed"],
pch=20, cex=.3, col = manhat.ord$col[manhat.ord$type=="typed"])
axis(2)
abline(h=0)
SigNifSNPs <- as.character(GWAS[GWAS$neg.logp > Lstringent.thresh & GWAS$type=="typed", "SNP"])
#Add legend
legend("topright",c("Bonferroni Corrected Threshold*", "Less Stringent Threshold**"),
border="black", col=c("gray60", "gray60"), pch=c(0, 0), lwd=c(1,1),
lty=c(1,2), pt.cex=c(0,0), bty="o", cex=0.7)
#Add chromosome number
text(text.pos/xscale, -.3, seq(1,22,by=1), xpd=TRUE, cex=1)
#Add bonferroni line
abline(h=bonferroni.thresh, untf = FALSE, col = "gray60")
#Add "less stringent" line
abline(h=Lstringent.thresh, untf = FALSE, col = "gray60", lty = 2 )
#Plotting detected genes
#Were any genes detected?
if (length(SigNifSNPs)>0){
sig.snps <- manhat.ord[,'SNP'] %in% SigNifSNPs
points(manhat.ord$pos[sig.snps]/xscale,
manhat.ord$neg.logp[sig.snps],
pch=15,col=col.detected, bg=col.detected,cex=0.5)
text(manhat.ord$pos[sig.snps]/xscale,
manhat.ord$neg.logp[sig.snps],
as.character(manhat.ord[sig.snps,1]), col=col.text, offset=1, adj=-.1, cex=.7)
}
}
p <- GWAS.manhattan(GWAS.comb)
typCETP <- map2gene("CETP", coords = genes, SNPs = GWAS.output)
GWAS.output
genes
typCETP <- map2gene("CETP", coords = genes, SNPs = GWAS.output)
# source file
source("map2gene.R")
#Subset for CETP SNPs
typCETP <- map2gene("CETP", coords = genes, SNPs = GWAS.output)
# === GWAS tutorial ============================================================
# authors: Umayeer Milky, Severin Santana
# This code is an adaptation of the codes demonstrated by  Reed et al. (2015),
# Foulkes (2016), Lima (2017) & Marees et al.(2018). The
# purpose of this code is to familiarize ourselves with the different
# steps involved in a GWAS analysis in R.
# === Installing Packages ======================================================
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("snpStats")
BiocManager::install("SNPRelate")
BiocManager::install("rtracklayer")
BiocManager::install("biomaRt")
install.packages(c("plyr", "LDheatmap", "doParallel", "ggplot2"))
install.packages(c("GenABEL.data_1.0.0.tar.gz", "GenABEL_1.8-0.tar.gz"),
repos = NULL, type="source")
library("snpStats")
library("SNPRelate")
library("biomaRt")
library("plyr")
library("GenABEL")
library("LDheatmap")
library("doParallel")
library("ggplot2")
library("survival")
library("rtracklayer")
# === customizing data directory ===============================================
dir.path <- getwd()
# === folder management ========================================================
folder.names <- c("a.raw.data", "b.filtered.data", "c.generated.data",
"d.GWAS", "e.graphics")
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
# ******************************************************************************
#path names to variables
p.data.raw <- paste(dir.path, "/", folder.names[1], "/", sep = "")
p.data.filtered <- paste(dir.path, "/", folder.names[2], "/", sep = "")
p.data.generated <- paste(dir.path, "/", folder.names[3], "/", sep = "")
p.gwas <- paste(dir.path, "/", folder.names[4], "/", sep = "")
p.graphics <- paste(dir.path, "/", folder.names[5], "/", sep = "")
# === Input Files ==============================================================
#returns character objects that are a formatted combination of input values
gwas.data <- lapply(c(bed="bed", bim="bim", fam="fam", gds="gds"),
function(n) sprintf("%s/GWAStutorial.%s",
p.data.raw, n))
clinical.data <- sprintf("%s/GWAStutorial_clinical.csv", p.data.raw)
onethou.fn <- lapply(c(info='info',ped='ped'),
function(n) sprintf("%s/chr16_1000g_CEU.%s",
p.data.raw, n))
protein.coding.coords.fname <- sprintf("%s/ProCodgene_coords.csv", p.data.raw)
# === Output Files =============================================================
gwaa.out <- sprintf("%s/GWASout.txt", p.gwas)
impute.out.fname <- sprintf("%s/Imputation.csv", p.gwas)
# on to script 2.Reading.raw.data.R
# === Reading Data in R ========================================================
# Read PLINK files to create a list
# PLINK is a genome association analysis toolkit
# bed files contain individual genotypes
# bin files contain the locations of all SNPs in the data in the genome
# fam files contain information about the individual including family pedigrees
geno.me <- read.plink(gwas.data$bed, gwas.data$bim, gwas.data$fam)
# creating the genotyope object from the geno.me list
genotype <- geno.me$genotype
print(genotype)
head(genotype)
# obtain the SNP information from geno list
geno.bim <- geno.me$map
colnames(geno.bim) <- c("chr", "SNP", "gen.dist", "position", "A1", "A2")
print(head(geno.bim))
#creating SNP object from the geno.me list
SNP.genome <- geno.me$map
colnames(SNP.genome) <- c("chromosome", "SNP", "gen.dist", "position", "N1",
"N2")
print(head(SNP.genome))
#removing raw data to create space
rm(geno.me)
#reading phenotype data from the clinical file
#apparently using colClasses saves data importing time
#Also, cannot subset genotype without rearranging using colClasses first
phenotype <- read.csv(clinical.data,
colClasses = c("character", "factor", "factor",
rep("numeric", 4)))
rownames(phenotype) <- phenotype$FamID
head(phenotype)
#subsetting genotype to only include individuals with known phenotype
genotype.s <- genotype[phenotype$FamID, ]
### we need to save these objects somehow so they can run in future scripts
# the authors use this
# Write genotype, genoBim, clinical for future use
# does not work ####
#save(genotype, geno.bim, phenotype, file = working.data.fname(1))
# on to script 3.Data.filtering
# === Quality Check & Filtering ================================================
## SNP level-filtering
# We want to filter out the common alleles from the SNPs. This
# eliminates/reduces homogeneity from the sample and helps to draw statistically
# significant relationship between the SNP and the trait (phenotype) we are
# interested in. Another thing we use is the call rate. Call rate for a SNP
# is the proportion of individuals in the study for which the corresponding SNP
# information is not missing (i.e. no. of individuals with SNP information/total
# number of individuals in the study). These account for errors in genotyping.
# Creating column summary statistics of SNP information
snpsummary.col <- col.summary(genotype.s)
head(col.summary)
# Setting thresholds for the filtering
call <- 0.95 # SNPs with 5% missing data is retained after filtering.
minor.f <- 0.01
# Filtering the SNP data
fil.genotype <- with(snpsummary.col, (!is.na(MAF) & MAF > minor.f)
& Call.rate >= call)
fil.genotype[is.na(fil.genotype)] <- FALSE #Remove NA values
print(ncol(genotype.s)-sum(fil.genotype)) # 203287 SNPs will be removed
#Subset genotype.s for SNPs those meet the MAF and call rate criteria
genotype.s <- genotype.s[,fil.genotype]
# Subset the SNP summary data for SNPs those meet the MAF and call rate criteria
snpsummary.col <- snpsummary.col[fil.genotype,]
print(genotype.s) #658186 SNPs are remaining
## Sample level filtering
# Want to get rid of individuals with missing data and other criteria such as
# racial, ethnic, or gender ambiguity (GWAS is population dependent)
# We also get rid of contaminated samples (this varies)
# We will use call rate and heterozygosity as thresholds for filtering here.
# Individuals who are missing genotype data for more than 5% of the
# typed SNPs are removed by the 95% call rate. Excess
# heterozygosity across typed SNPs within an individual may be an indication of
# poor sample quality, while deficient heterozygosity can indicate inbreeding or
# other substructure in that person. Thus, samples with an inbreeding
# coefficient |F| = (1 - O/E) > 0.10 are removed, where O and E are respectively
# the observed and expected counts of heterozygous SNPs within an individual.
# Creating row summary statistics for the sample
snpsummary.row <- row.summary(genotype.s)
# Calculating the inbreeding coefficient for the sample and adding it to the
# row summary statistics for the sample
MAF <- snpsummary.col$MAF
callmatrix <- !is.na(genotype.s)
hetExp <- callmatrix %*% (2*MAF*(1-MAF))
hetObs <- with(snpsummary.row, Heterozygosity*(ncol(genotype.s))*Call.rate)
snpsummary.row$hetF <- 1-(hetObs/hetExp)
# Setting thresholds for sample filtering
samp.call <- 0.95       # 95% call rate
het.cutoff <- 0.10      # Inbreeding coefficient cutoff
#Filtering sample based on threshold
fil.sample <- with(snpsummary.row, !is.na(Call.rate) & Call.rate > samp.call &
abs(hetF) <= het.cutoff)
fil.sample[is.na(fil.sample)] <- FALSE   #removing NAs from the sample
print(nrow(genotype.s)-sum(fil.sample))  # 0 subjects removed
# Subset genotype and phenotype data for subjects meeting the heterozygosity and
# call rate criteria
genotype.s <- genotype.s[fil.sample,]
phenotype <- phenotype[rownames(genotype.s),]
head(genotype.s)
# Now we will further filter the sample for relatedness and redundancy.
# We will use the linkage disequilibrium as a threshold to remove redundancy.
# We will use the kinship threshold to remove related individuals from the
# sample pool.
kin.cutoff <- 0.1  # Kinship Cut-Off based on IBD coefficient
ld.cutoff <- 0.2   # LD cut-off. 0.2 seems to be the standard in GWAS.
## Creating the gds files that are required for the SNPRelate functions
# Creating gds file as SNPRelate functions require gds files to run
# Converting from PLINK to GDS
##### we should make a check for this so it only runs if the file is missing?
snpgdsBED2GDS(gwas.data$bed, gwas.data$fam, gwas.data$bim, gwas.data$gds)
genofile <- snpgdsOpen(gwas.data$gds, readonly = FALSE)
# Removing automatically added "-1" suffixes
gds.ids <- read.gdsn(index.gdsn(genofile, "sample.id"))
gds.ids <- sub("-1", "", gds.ids)
add.gdsn(genofile, "sample.id", gds.ids, replace = TRUE)
#Prune SNPs for IBD analysis
set.seed(1000)
genosample.ids <- rownames(genotype.s)
snpSUB <- snpgdsLDpruning(genofile, ld.threshold = ld.cutoff,
sample.id = genosample.ids,
snp.id = colnames(genotype.s))
snpset.ibd <- unlist(snpSUB, use.names = FALSE)
cat(length(snpset.ibd), "will be used in IBD analysis\n") # expect 72890 SNP's
## Find IBD coefficients using Method of Moments procedure.
## Method of Moments is a method of estimating population parameters
## Include pairwise kinship
ibd <- snpgdsIBDMoM(genofile, kinship = TRUE,
sample.id = genosample.ids,
snp.id = snpset.ibd,
num.thread = 1)
ibdcoeff <- snpgdsIBDSelection(ibd) # Pairwise sample comparison
head(ibdcoeff)
# check if there are any candidates for relatedness
ibdcoeff <- ibdcoeff [ibdcoeff$kinship >= kin.cutoff, ]
##iteratively remove samples with high kinship starting with the sample with
## the most pairings. The statistical significance of a GWAS analysis is
## impaired by a high degree of relatedness within the population. So, we want
## to eliminate kinship as much as we possibly can.
related.samples <- NULL
while (nrow(ibdcoeff) > 0 ) {
## count the number of occurrences of each and take the top one
sample.counts <- arrange(count(c(ibdcoeff$ID1, ibdcoeff$ID2)), -freq)
rm.sample <- sample.counts[1, "x"]
cat("Removing sample", as.character(rm.sample), "too closely related to",
sample.counts[1, "freq"], "other samples. \n")
## remove from ibdcoeff and add to list
ibdcoeff <- ibdcoeff[ibdcoeff$ID1 !=rm.sample & ibdcoeff$ID2 != rm.sample,]
related.samples <- c(as.character(rm.sample), related.samples)
}
## filter genotype and clinical to include only unrelated samples
genotype.s <- genotype.s[!(rownames(genotype.s) %in% related.samples),]
phenotype <- phenotype[!(phenotype$FamID %in% related.samples),]
genosample.ids <- rownames(genotype.s)
cat(length(related.samples), "similar samples removed due to
correlation coefficient >=", kin.cutoff, "\n")
print(genotype.s) # except all 1401 subject remain
# checking for ancestry. PCA is one approach to visualizing and classifying
# individuals into ancestry groups based on their observed genetic makeup.
# This is done to eliminate sample-level errors. For e.g. There could be an
# individual who do not fall within a racial/ethnic cluster despite claiming
# to be of a certain racial/ethnic group.
## find PCA matrix
pca.anc <- snpgdsPCA(genofile, sample.id = genosample.ids, snp.id = snpset.ibd,
num.thread = 1)
## create data frame of first two principal components
pctab <- data.frame(sample.id = pca.anc$sample.id,
PC1 = pca.anc$eigenvect[,1], # the first eigenvector
PC2 = pca.anc$eigenvect[,2], # the second eigenvector
stringsAsFactors = FALSE)
# plot the first two principal components
#### I dont know what this plot means lol #####
#### can you add the code to save this plot as a pdf? #####
plot(pctab$PC2, pctab$PC1, xlab = "Principal Component 2",
ylab = "Principal Component 1", main = "Ancestry Plot")
# testing for violations of Hardy-Weinberg equilibrium (HWE).
# Violations of HWE can be an indication of genotyping error so it is common
# practice to remove SNPs for which HWE is violated.
# setting threshold for HWE test p < 1x10^10-6
HWE.thres <- 10^-6
# filter based on HWE
CADcontrols <- phenotype[phenotype$CAD==0, 'FamID' ]
snpsum.col.cont <- col.summary(genotype.s[CADcontrols,])
HWE.use <- with(snpsum.col.cont, !is.na(z.HWE) & ( abs(z.HWE) < abs( qnorm(HWE.thres/2))))
rm(snpsum.col.cont)
HWE.use[is.na(HWE.use)] <- FALSE          # Remove NA's as well
cat(ncol(genotype.s)-sum(HWE.use),"SNPs will be removed due to high HWE.\n")
## subset genotype and SNP summary data for SNPs that pass HWE criteria
genotype.s <- genotype.s[,HWE.use]
print(genotype.s)
### Here we could save the filtered genotype.s as a clean csv?
# on to script 4.Data.generation
# === Data Generation ==========================================================
## Principal Components (PCs) based on observed genotype data capture
## information on substructure - genetic diversity in an apparently homogenous
## population that is caused by population genetic history (migration,
## selection, and/or ethnic integration). These substructures cannot be inferred
## from self-reported race and ethnicity variables.
## generating principal components for modeling
# set LD threshold to 0.2
ld.cutoff <- 0.2
set.seed(1000)
genosample.ids <- rownames(genotype.s)
snpSUB <- snpgdsLDpruning(genofile, ld.threshold = ld.cutoff,
sample.id = genosample.ids, # only analyze filtered samples
snp.id = colnames(genotype.s)) # only analyze filtered samples
snpset.pca <- unlist(snpSUB, use.names = FALSE)
cat(length(snpset.pca), "\n") #72665 SNPs will be used in PCA analysis
pca <- snpgdsPCA(genofile, sample.id = genosample.ids,
snp.id = snpset.pca, num.thread = 1)
## find and record first 10 principal components
## pcs will be a N:10 matrix. Each column is a principal component.
pcs <- data.frame(FAMID = pca$sample.id, pca$eigenvect[,1:10],
stringsAsFactors = FALSE)
colnames(pcs)[2:11] <- paste("pc", 1:10, sep ="")
# rename "FAMID" to "FamID" to match other files
names(pcs)[names(pcs) == "FAMID"] <- "FamID"
print(head(pcs))
## Imputation of non-typed SNPs
## genotypes of untyped SNPs may have a functional relationship to the
## outcome and therefore provide additional power for identifying association.
## Imputation of SNPs involve estimating missing genotypes from the haplotype
## or genotype reference panel. Here, we use the 1000 Genomes data for this.
## read in 1000g data for given chromosome 16
thougeno <- read.pedfile(onethou.fn$ped, snps = onethou.fn$info, which = 1)
## obtain genotype data for given chromosome
geno.matrix <- thougeno$genotypes
## obtain the chromosome position for each SNP
support <- thougeno$map
colnames(support) <- c("SNP", "position", "N1", "N2")
head(support)
## imputation of non-typed 1000g SNPs
## subset for SNPs on given chromosome
pres.SNPS <- colnames(genotype.s)
pres.dat.chr <- geno.bim[geno.bim$SNP %in% pres.SNPS & geno.bim$chr==16,]
target.SNPS <- pres.dat.chr$SNP
## subset 1000g data for our SNPs
## "missing" and "present are snpMatrix objects needed for imputation rules
is.present <- colnames(geno.matrix) %in% target.SNPS
missing <- geno.matrix[,!is.present]
print(missing)
present <- geno.matrix[, is.present]
print(present)
## obtain positions of SNPs to be used for imputation rules
pos.present <- support$position[is.present]
pos.missing <- support$position[!is.present]
## calculate and store the imputation rules using snp.imputation()
rules <- snp.imputation(present, missing, pos.present, pos.missing)
# remove failed imputations
rules <- rules[can.impute(rules)]
cat("Imputation rules for", length(rules), "SNPs were estimated\n")
## quality control for imputation certainty and MAF
# set thresholds
r2threshold <- 0.7
minor <- 0.01
# filter on imputation certainty and MAF
rules <- rules[imputation.r2(rules) >= r2threshold]
cat(length(rules), "imputation rules remain after uncertain imputations were removed\n")
## 162628 imputation rules remain after uncertain imputation were removed
rules <- rules[imputation.maf(rules) >= minor]
cat(length(rules), "imputation rules remain after MAF filtering\n")
## obtain posterior expectation of genotypes of imputed SNPs
target <- genotype.s[, target.SNPS]
imputed <- impute.snps(rules, target, as.numeric = FALSE)
print(imputed)
# on to script 5.Data.analysis
# === Data analysis ============================================================
## installing packages
# They are in our GitHub Repository
### we could create a folder called "packages" and add them in there?
# association analysis of typed SNPs
# this is specific to the data and here we use the HDL-cholestrol as the trait
# merge clinical data and principal components to create phenotype table
pheno.sub <- merge.data.frame(phenotype,pcs)
# data frame => [FamID CAD sex age hdl...pc10]
# rank-based inverse normal transformation of hdl
pheno.sub$phenotype <- rntransform(pheno.sub$hdl, family = "gaussian")
# show that the assumptions of normality met after transformation
par(mfrow=c(1,2))
hist(pheno.sub$hdl, main = "Histogram of HDL", xlab = "HDL")
hist(pheno.sub$phenotype, main = "Histogram of Transformed HDL",
xlab = "Transformed HDL")
# remove columns that are unnecessary from the table
pheno.sub$hdl <- NULL
pheno.sub$ldl <- NULL
pheno.sub$tg <- NULL
pheno.sub$CAD <- NULL
# Rename columns to match names necessary for GWAS() function
names(pheno.sub)[names(pheno.sub ) == "FamID"] <- "id"
# Include only subjects with hdl data
pheno.sub <- pheno.sub[!is.na(pheno.sub$phenotype),]
# 1309 subjects identified to have phenotype data
print (head(pheno.sub))
# Reading GWAS output
GWAS.output <- read.table(gwaa.out, sep = "",header=TRUE,
colClasses=c("character"))
head(GWAS.output)
# Calculating the -log10 of the p-values
GWAS.output$p.value <- as.numeric(GWAS.output$p.value)
GWAS.output$neg.logp <- -log10(GWAS.output$p.value)
head(GWAS.output)
GWAS.output <- merge(GWAS.output, geno.bim[,c("SNP", "chr", "position")],
by = "SNP")
head(GWAS.output)
rm(geno.bim)
GWAS.output <- arrange(GWAS.output, neg.logp)
print(head(GWAS.output))
rownames(pheno.sub) <- pheno.sub$id
imp <- snp.rhs.tests(phenotype ~ sex + age + pc1 + pc2 + pc3 + pc4 + pc5 + pc6 +
pc7 + pc8 + pc9 + pc10, family = "Gaussian",
data = pheno.sub, snp.data = target, rules = rules)
# Obtain p values for imputed SNPs
imp.results <- data.frame(SNP = imp@snp.names, p.value = p.value(imp),
stringsAsFactors = FALSE)
imp.results <- imp.results[!is.na(imp.results$p.value),]
imp.results
# Merge imputation testing results with support
impute.out <- merge(imp.results, support[,c("SNP", "position")])
impute.out$chr <- 16
impute.out
impute.out$type <- "imputed"
impute.out
# Calculating the -log10 of the imputed p-values
impute.out$neg.logp <- -log10(impute.out$p.value)
# Order by p-values
impute.out <- arrange(impute.out, p.value)
print(head(impute.out))
# source file
source("map2gene.R")
#Reading file containing protein coding gene coordinates
genes <- read.csv(protein.coding.coords.fname, stringsAsFactors = FALSE)
#Subset for CETP SNPs
impCETP <- map2gene("CETP", coords = genes, SNPs = impute.out)
# Filtering the imputed CETP SNP genotypes
impCETPgeno <- imputed[, impCETP$SNP]
GWAS.output$type <- "typed"
GWAS.comb <- rbind.fill(GWAS.output, impute.out)
head(GWAS.comb)
tail(GWAS.comb)
str(GWAS.comb)
#Subset for CETP SNPs
typCETP <- map2gene("CETP", coords = genes, SNPs = GWAS.output)
CETP <- rbind.fill(typCETP, impCETP)[,c("SNP", "p.value", "neg.logp", "chr",
"position", "type", "gene")]
print(CETP)
gc()
install.packages("survival")
# Manhattan plots are used to visualize GWA significance level by chromosome
# location. Visual inspection of this plot allows for identification of SNPs
# with relatively small p-values that are in regions with relatively large and
# non-significant p-values, suggesting potentially false findings.
# Multiple signals in the CETP region suggest that this may be a true signal.
source("Manhattan.plot.R")
par(mfrow = c(1,1))
source("Manhattan.plot.R")
par(mfrow = c(1,1))
p <- GWAS.manhattan(GWAS.comb)
p
GWAS.output$t.value <- as.numeric(GWAS.output$t.value)
lambda <- estlambda(GWAS.output$t.value^2, plot = TRUE, method = "median")
