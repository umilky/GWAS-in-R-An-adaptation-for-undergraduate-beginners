repos = NULL, type="source")
library("snpStats")
library("SNPRelate")
library("biomaRt")
library("plyr")
library("GenABEL")
library("LDheatmap")
library("doParallel")
library("ggplot2")
library("survival")
library("rtracklayer")
# === Customizing data directory ===============================================
main.dir <- getwd()
# === Folder management ========================================================
folder.names <- c("a.raw.data", "b.working.data", "c.GWAS", "d.graphics")
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
# ******************************************************************************
# Creation of paths to each folder in repository
p.data.raw <- paste(main.dir, "/", folder.names[1], "/", sep = "")
p.work.data <- paste(main.dir, "/", folder.names[2], "/", sep = "")
p.gwas <- paste(main.dir, "/", folder.names[3], "/", sep = "")
p.graphics <- paste(main.dir, "/", folder.names[4], "/", sep = "")
# === Input Files ==============================================================
# Create character objects that are a formatted combination of input values
gwas.data <- lapply(c(bed="bed", bim="bim", fam="fam", gds="gds"),
function(n) sprintf("%s/GWAStutorial.%s",
p.data.raw, n))
clinical.data <- sprintf("%s/GWAStutorial_clinical.csv", p.data.raw)
onethou.fn <- lapply(c(info='info',ped='ped'),
function(n) sprintf("%s/chr16_1000g_CEU.%s",
p.data.raw, n))
# === Output Files =============================================================
gwaa.out <- sprintf("%s/GWASout.txt", p.gwas)
impute.out.fname <- sprintf("%s/Imputation.csv", p.gwas)
# Working data saved between each script so each script can run independently.
# Use save(data, file=working.data.fname(num)) to save data between scripts.
working.data.fname <- function(num) { sprintf("%s/working.%s.Rdata",
p.work.data, num) }
# on to script 2.Reading.raw.data.R
#___ end _______________________________________________________________________
# === Reading Data in R ========================================================
# *Note 1.Main.R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# This scrips creates and formats objects out of raw data for
# analysis in future scripts.
# Objects involving genomic data and phenotype data are created in this script.
# 1) Genomic data creation
# 2) Phenotype data creation
# 3) Data manipulation
# === 1) Genomic data creation =================================================
# Reading of PLINK files to create a list of genomic data.
# PLINK is a genome association analysis toolkit.
# .bed files contain individual genotypes.
# .bin files contain the locations of all SNPs in the data in the genome.
# .fam files contain information about the individual including family pedigrees.
# Creating genomic data matrix from PLINK
geno.me <- read.plink(gwas.data$bed, gwas.data$bim, gwas.data$fam)
# Creating the genotype matrix from the geno.me matrix
genotype <- geno.me$genotype
head(genotype)
# Creating a data frame for the SNP information from geno.me matrix
geno.bim <- geno.me$map
# renaming of column names for later data frame merge
colnames(geno.bim) <- c("chr", "SNP", "gen.dist", "position", "A1", "A2")
print(head(geno.bim))
# Creating SNP dataframe from the geno.me list
SNP.genome <- geno.me$map
# Renaming of column names for later data frame merge
colnames(SNP.genome) <- c("chromosome", "SNP", "gen.dist", "position", "A1",
"A2")
print(head(SNP.genome))
# === 2) Phenotype data creation================================================
# Reading phenotype data from the clinical data csv file.
# Using colClasses saves data importing time
# colClasses creates a vector of column classes used for tabular reading.
# This is required for subsetting genotype in the next step.
# Creating data frame from phenotype csv file
phenotype <- read.csv(clinical.data,
colClasses = c("character", "factor", "factor",
rep("numeric", 4)))
rownames(phenotype) <- phenotype$FamID
head(phenotype)
# === 3) Data manipulation =====================================================
# Subsetting genotype object to only include individuals with known phenotype
genotype.s <- genotype[phenotype$FamID, ]
# ******************************************************************************
# Write genotype.s, geno.bim & phenotype for future use.
# *Note this function can take a few minutes
save(genotype.s, geno.bim, phenotype, file = working.data.fname(2))
# On to script 3.Data.filtering.R
#___ end _______________________________________________________________________
# === Data Quality Check & Filtering ===========================================
# *Note 1.Main. R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# Load data created in previous script, 2.Reading.raw.data.R
load(working.data.fname(2))
# The following script performs quality checks and filtering of genomic data
# using industry standard test such that fair analysis can be performed.
# Refer to table 1 in the accompaning paper for a more detailed explanation.
# 1) SNP level-filtering: Minor Allele Frequency and Call Rate
# 2) Sample level-filtering: Call Rate and Heterozygosity
# 3) Sample level-filtering: Relatedness
# 4) Sample level-filtering: Ancestry
# 5) SNP level-filtering: Hardy-Weinberg equilibrium
# === 1) SNP level-filtering: Minor Allele Frequency and Call Rate =============
# We want to filter out the common alleles from the SNPs. This
# eliminates/reduces homogeneity from the sample and helps to draw statistically
# significant relationship between the SNP and the trait (phenotype) we are
# interested in. Another thing we use is the call rate. Call rate for a SNP
# is the proportion of individuals in the study for which the corresponding SNP
# information is not missing (i.e. no. of individuals with SNP information/total
# number of individuals in the study). These account for errors in genotyping.
# Creating column summary statistics of SNP information
snpsummary.col <- col.summary(genotype.s)
head(snpsummary.col)
# Setting thresholds for filtering
call <- 0.95 # SNPs with 5% missing data is retained after filtering.
minor.f <- 0.01
# Filtering SNP data by minor allele frequency(MAF) and call rate
fil.genotype <- with(snpsummary.col, (!is.na(MAF) & MAF > minor.f)
& Call.rate >= call)
fil.genotype[is.na(fil.genotype)] <- FALSE #Remove NA values
print(ncol(genotype.s)-sum(fil.genotype)) # 203287 SNPs will be removed
# Subset genotype.s for SNPs that meet the minor allele frequency(MAF)
# and call rate criteria.
genotype.s <- genotype.s[,fil.genotype]
# Subset the SNP summary data for SNPs those meet the MAF and call rate criteria
snpsummary.col <- snpsummary.col[fil.genotype,]
print(genotype.s) #658186 SNPs are remaining
# === 2) Sample level-filtering: Call Rate and Heterozygosity ==================
# Filtering to get rid of individuals with missing data and other criteria such
# as racial, ethnic, or gender ambiguity (GWAS is population dependent).
# We also get rid of contaminated samples (this varies)
# We will use call rate and heterozygosity as thresholds for filtering here.
# Individuals who are missing genotype data for more than 5% of the
# typed SNPs are removed by the 95% call rate. Excess
# heterozygosity across typed SNPs within an individual may be an indication of
# poor sample quality, while deficient heterozygosity can indicate inbreeding or
# other substructure in that person. Thus, samples with an inbreeding
# coefficient |F| = (1 - O/E) > 0.10 are removed, where O and E are respectively
# the observed and expected counts of heterozygous SNPs within an individual.
# Creating row summary statistics for the sample
snpsummary.row <- row.summary(genotype.s)
# Calculating the inbreeding coefficient for the sample and adding it to the
# row summary statistics for the sample.
MAF <- snpsummary.col$MAF
callmatrix <- !is.na(genotype.s)
hetExp <- callmatrix %*% (2*MAF*(1-MAF))
hetObs <- with(snpsummary.row, Heterozygosity*(ncol(genotype.s))*Call.rate)
snpsummary.row$hetF <- 1-(hetObs/hetExp)
# Setting thresholds for sample filtering
samp.call <- 0.95       # 95% call rate
het.cutoff <- 0.10      # Inbreeding coefficient cutoff
# Filtering sample based on call rate and heterozygosity
fil.sample <- with(snpsummary.row, !is.na(Call.rate) & Call.rate > samp.call &
abs(hetF) <= het.cutoff)
fil.sample[is.na(fil.sample)] <- FALSE   #removing NAs from the sample
print(nrow(genotype.s)-sum(fil.sample))  # 0 subjects removed
# Subset genotype and phenotype data for subjects meeting the heterozygosity and
# call rate criteria.
genotype.s <- genotype.s[fil.sample,]
phenotype <- phenotype[rownames(genotype.s),]
head(genotype.s)
# === 3) Sample level-filtering: Relatedness  ==================================
# Now we will further filter the sample for relatedness.
# We will use the linkage disequilibrium as a threshold to remove redundancy.
# We will use the kinship threshold to remove related individuals from the
# sample pool.
# Setting thresholds for kinship and LD
kin.cutoff <- 0.1  # Kinship Cut-Off based on IBD coefficient
ld.cutoff <- 0.2   # LD cut-off. 0.2 seems to be the standard in GWAS.
# Creating gds which are a combination of the PLINK files
# SNPRelate functions require gds files to run
# Converting from PLINK to GDS
snpgdsBED2GDS(gwas.data$bed, gwas.data$fam, gwas.data$bim, gwas.data$gds)
genofile <- snpgdsOpen(gwas.data$gds, readonly = FALSE)
# Removing automatically added "-1" suffixes
gds.ids <- read.gdsn(index.gdsn(genofile, "sample.id"))
gds.ids <- sub("-1", "", gds.ids)
add.gdsn(genofile, "sample.id", gds.ids, replace = TRUE)
# Prune SNPs for IBD analysis
# Set seed for reproducibility
set.seed(1000)
# Create vector of sample ids from genomic data
genosample.ids <- rownames(genotype.s)
snpSUB <- snpgdsLDpruning(genofile, ld.threshold = ld.cutoff,
sample.id = genosample.ids,
snp.id = colnames(genotype.s))
snpset.ibd <- unlist(snpSUB, use.names = FALSE)
cat(length(snpset.ibd), "will be used in IBD analysis\n") # expect 72890 SNP's
# Find IBD coefficients using Method of Moments procedure.
# Method of Moments is a method of estimating population parameters
# include pairwise kinship.
ibd <- snpgdsIBDMoM(genofile, kinship = TRUE,
sample.id = genosample.ids,
snp.id = snpset.ibd,
num.thread = 1)
ibdcoeff <- snpgdsIBDSelection(ibd) # Pairwise sample comparison
head(ibdcoeff)
# Check if there are any candidates for relatedness
ibdcoeff <- ibdcoeff [ibdcoeff$kinship >= kin.cutoff, ]
# Iteratively remove samples with high kinship starting with the sample with
# the most pairings. The statistical significance of a GWAS analysis is
# impaired by a high degree of relatedness within the population. So, we want
# to eliminate kinship as much as we possibly can.
# create object for samples
related.samples <- NULL
# Run iterative loop to add samples to related.samples from ibdcoeff
while (nrow(ibdcoeff) > 0 ) {
# Count the number of occurrences of each and take the top one
sample.counts <- arrange(count(c(ibdcoeff$ID1, ibdcoeff$ID2)), -freq)
rm.sample <- sample.counts[1, "x"]
cat("Removing sample", as.character(rm.sample), "too closely related to",
sample.counts[1, "freq"], "other samples. \n")
# Remove from ibdcoeff and add to list
ibdcoeff <- ibdcoeff[ibdcoeff$ID1 !=rm.sample & ibdcoeff$ID2 != rm.sample,]
related.samples <- c(as.character(rm.sample), related.samples)
}
# Subset genotype and phenotype to include only unrelated samples
genotype.s <- genotype.s[!(rownames(genotype.s) %in% related.samples),]
phenotype <- phenotype[!(phenotype$FamID %in% related.samples),]
genosample.ids <- rownames(genotype.s)
cat(length(related.samples), "similar samples removed due to
correlation coefficient >=", kin.cutoff, "\n")
print(genotype.s) # except all 1401 subject remain
# === 4) Sample level-filtering: Ancestry ======================================
# Checking for ancestry within sample. PCA is one approach to
# visualizing and classifying  individuals into ancestry groups based on their
# observed genetic makeup. This is done to eliminate sample-level errors.
# For e.g. There could be an individual who do not fall within a racial/ethnic
# cluster despite claiming to be of a certain racial/ethnic group.
# Find PCA matrix
pca.anc <- snpgdsPCA(genofile, sample.id = genosample.ids, snp.id = snpset.ibd,
num.thread = 1)
# Create data frame of first two principal components
pctab <- data.frame(sample.id = pca.anc$sample.id,
PC1 = pca.anc$eigenvect[,1], # the first eigenvector
PC2 = pca.anc$eigenvect[,2], # the second eigenvector
stringsAsFactors = FALSE)
# Plot the first two principal components
# Save plot as pdf in graphics folder
pdf(paste(p.graphics, "pc.plot.pdf", sep = ""))
pc.plot <- plot(pctab$PC2, pctab$PC1, xlab = "Principal Component 2",
ylab = "Principal Component 1", main = "Ancestry Plot")
?dev.off()
# === 5) SNP level-filtering: Hardy-Weinberg equilibrium =======================
# Testing for violations of Hardy-Weinberg equilibrium (HWE).
# Violations of HWE can be an indication of genotyping error so it is common
# practice to remove SNPs for which HWE is violated.
# Setting threshold for HWE test p < 1x10^10-6
HWE.thres <- 10^-6
# Filter based on population controls, in this case individuals without
# coronary artery disease(CAD).
CADcontrols <- phenotype[phenotype$CAD==0, 'FamID' ]
snpsum.col.cont <- col.summary(genotype.s[CADcontrols,])
# Filter based on HWE
HWE.use <- with(snpsum.col.cont,
!is.na(z.HWE) & ( abs(z.HWE) < abs( qnorm(HWE.thres/2))))
HWE.use[is.na(HWE.use)] <- FALSE          # Remove NA's as well
cat(ncol(genotype.s)-sum(HWE.use),"SNPs will be removed due to high HWE.\n")
# Subset genotype and SNP summary data for SNPs that pass HWE criteria
genotype.s <- genotype.s[,HWE.use] #656890 SNPs remain
print(head(genotype.s))
# ******************************************************************************
# Write genotype.s, geno.bim, genofile & phenotype for future use.
# *Note this function can take a few minutes
save(genotype.s, geno.bim, genofile, phenotype, file = working.data.fname(3))
# on to script 4.Data.generation.R
#___ end _______________________________________________________________________
# === Data Generation ==========================================================
# *Note 1.Main. R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# Load data created in previous script, 3.Data.filtering.R
load(working.data.fname(3))
# The following script generates principle components needed for genome-wide
# association analyses along with imputed SNPs which are usefull for association
# identification. The imputed SNPs will be visualized on the Manhattan plot.
# 1) Principal Component Generation
# 2) Imputation of non-typed SNPs
# === 1) Principal Component Generation ========================================
# Principal Components (PCs) based on observed genotype data capture
# information on substructure - genetic diversity in an apparently homogenous
# population that is caused by population genetic history (migration,
# selection, and/or ethnic integration). These substructures cannot be inferred
# from self-reported race and ethnicity variables.
# Generating principal components for modeling
# set LD threshold to 0.2
ld.cutoff <- 0.2
# Set seed for reproducibility
set.seed(1000)
# Create vector of sample ids from genomic data
genosample.ids <- rownames(genotype.s)
# Prune SNPs
snpSUB <- snpgdsLDpruning(genofile, ld.threshold = ld.cutoff,
sample.id = genosample.ids,
snp.id = colnames(genotype.s))
snpset.pca <- unlist(snpSUB, use.names = FALSE)
cat(length(snpset.pca), "\n") #72665 SNPs will be used in PCA analysis
# Generate principle components from SNPs within LD threshold
pca <- snpgdsPCA(genofile, sample.id = genosample.ids,
snp.id = snpset.pca, num.thread = 1)
# Find and record first 10 principal components
# pcs will be a N:10 matrix. Each column is a principal component.
pcs <- data.frame(FAMID = pca$sample.id, pca$eigenvect[,1:10],
stringsAsFactors = FALSE)
colnames(pcs)[2:11] <- paste("pc", 1:10, sep ="")
# Rename "FAMID" to "FamID" to match other files
names(pcs)[names(pcs) == "FAMID"] <- "FamID"
print(head(pcs))
# === 2) Imputation of non-typed SNPs ==========================================
# Genotypes of untyped SNPs may have a functional relationship to the
# outcome and therefore provide additional power for identifying association.
# Imputation of SNPs involve estimating missing genotypes from the haplotype
# or genotype reference panel. Here, we use the 1000 Genomes data for this.
# Read in 1000g data for given chromosome 16
thougeno <- read.pedfile(onethou.fn$ped, snps = onethou.fn$info, which = 1)
# Obtain genotype data for given chromosome
geno.matrix <- thougeno$genotypes
# Obtain the chromosome position for each SNP
support <- thougeno$map
colnames(support) <- c("SNP", "position", "N1", "N2")
head(support)
# Imputation of non-typed 1000g SNPs
# Subset for SNPs on given chromosome
pres.SNPS <- colnames(genotype.s)
pres.dat.chr <- geno.bim[geno.bim$SNP %in% pres.SNPS & geno.bim$chr==16,]
target.SNPS <- pres.dat.chr$SNP
# Subset 1000g data for our SNPs
# "missing" and "present" are snpMatrix objects needed for imputation rules
is.present <- colnames(geno.matrix) %in% target.SNPS
missing <- geno.matrix[,!is.present]
print(missing)
present <- geno.matrix[, is.present]
print(present)
# Obtain positions of SNPs to be used for imputation rules
pos.present <- support$position[is.present]
pos.missing <- support$position[!is.present]
# Calculate and store the imputation rules using snp.imputation()
rules <- snp.imputation(present, missing, pos.present, pos.missing)
# Remove failed imputations
rules <- rules[can.impute(rules)]
cat("Imputation rules for", length(rules), "SNPs were estimated\n")
# Quality control for imputation certainty and MAF
# Set thresholds
r2threshold <- 0.7
minor <- 0.01
# Filter on imputation certainty and MAF
rules <- rules[imputation.r2(rules) >= r2threshold]
cat(length(rules),
"imputation rules remain after uncertain imputations were removed\n")
# 162565 imputation rules remain after uncertain imputation were removed
rules <- rules[imputation.maf(rules) >= minor]
cat(length(rules), "imputation rules remain after MAF filtering\n")
# 162565 imputation rules remain after MAF filtering
# Obtain posterior expectation of genotypes of imputed SNPs
target <- genotype.s[, target.SNPS]
imputed <- impute.snps(rules, target, as.numeric = FALSE)
print(imputed)
# ******************************************************************************
# Write genotype.s, geno.bim, genofile, phenotype, pcs, support & imputed
# for future use.
# *Note this function can take a few minutes
save(genotype.s, geno.bim, genofile, phenotype, pcs, support, imputed,
file = working.data.fname(4))
# On to script 5.Data.analysis.R
#___ end _______________________________________________________________________
# === Data Analysis ============================================================
# *Note 1.Main. R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# Load data created in previous script, 4.Data.Generation.R
load(working.data.fname(4))
# The following script performs a genome-wide association analysis(GWAA) of
# typed SNPs this is specific to the data and here we use the HDL-cholestrol
# as the trait. The results of the GWAA are then sorted into a data frame for
# visualization in the next script. An association analysis is  also run for the
# imputed SNPs which are also sorted into a data frame for further analysis.
# 1) Manipulation of Phenotype Data
# 2) Run GWAA
# 3) GWAA Object Creation
# 4) Association analysis of imputed SNPs
# 5) Integrating typed and imputed SNPs
# === 1) Manipulation of Phenotype Data ========================================
# Creating a suitable table to run a genome-wide association analysis(GWAA) that
# includes phenotype data and principle components. The data is also visualized
# to check for normality and adjusted accordingly.
# Merge phenotype data and principal components to create phenotype table
pheno.sub <- merge.data.frame(phenotype,pcs)
# data frame => [FamID CAD sex age hdl...pc10]
# Rank-based inverse normal transformation of HDL
pheno.sub$phenotype <- rntransform(pheno.sub$hdl, family = "gaussian")
# Show that the assumptions of normality met after transformation
par(mfrow=c(1,2))
hist(pheno.sub$hdl, main = "Histogram of HDL", xlab = "HDL")
hist(pheno.sub$phenotype, main = "Histogram of Transformed HDL",
xlab = "Transformed HDL")
# Remove columns that are unnecessary from the table
# Age and sex are left in table as they established covariates for HDL level
pheno.sub$hdl <- NULL
pheno.sub$ldl <- NULL
pheno.sub$tg <- NULL
pheno.sub$CAD <- NULL
# Rename columns to match names necessary for GWAS() function
names(pheno.sub)[names(pheno.sub ) == "FamID"] <- "id"
# Include only subjects with HDL data
pheno.sub <- pheno.sub[!is.na(pheno.sub$phenotype),]
# 1309 subjects identified to have phenotype data
print (head(pheno.sub))
# Reading GWAA output
GWAS.output <- read.table(gwaa.out, sep = "",header=TRUE,
colClasses=c("character"))
head(GWAS.output)
# Calculating the -log10 of the p-values
GWAS.output$p.value <- as.numeric(GWAS.output$p.value)
GWAS.output$neg.logp <- -log10(GWAS.output$p.value)
head(GWAS.output)
# Merge output with geno.bim by SNP name to add position and chromosome number
GWAS.output <- merge(GWAS.output, geno.bim[,c("SNP", "chr", "position")],
by = "SNP")
head(GWAS.output)
# Tagging SNPs by type
GWAS.output$type <- "typed"
# Data check to make sure plots can run correctly.
GWAS.output$t.value <- as.numeric(GWAS.output$t.value)
# Order SNPs by significance
GWAS.output <- arrange(GWAS.output, neg.logp)
print(head(GWAS.output))
# === 4) Association analysis of imputed SNPs ==================================
# Association analysis of imputed SNPs to be included in Manhattan plot.
# Imputed SNPs will be compared to the same threshold as the typed SNPs
# Setting row names for pheno.sub
rownames(pheno.sub) <- pheno.sub$id
# Performing association testing for the imputed SNPs
imp <- snp.rhs.tests(phenotype ~ sex + age + pc1 + pc2 + pc3 + pc4 + pc5 + pc6 +
pc7 + pc8 + pc9 + pc10, family = "Gaussian",
data = pheno.sub, snp.data = target, rules = rules)
# Obtain p values for imputed SNPs
imp.results <- data.frame(SNP = imp@snp.names, p.value = p.value(imp),
stringsAsFactors = FALSE)
imp.results <- imp.results[!is.na(imp.results$p.value),]
# Merge imputation testing results with support
impute.out <- merge(imp.results, support[,c("SNP", "position")])
# Subsetting for chromosome 16 based on available 1000 Genomes data
impute.out$chr <- 16
# Tagging SNPs by type
impute.out$type <- "imputed"
# Calculating the -log10 of the imputed p-values
impute.out$neg.logp <- -log10(impute.out$p.value)
# Order by p-values
impute.out <- arrange(impute.out, p.value)
print(head(impute.out))
# === 5) Integrating typed and imputed SNPs  ==================================
# Merging of typed and imputed SNPs for visualization in next script.
# Combination of typed and imputed data frames
GWAS.comb <- rbind.fill(GWAS.output, impute.out)
head(GWAS.comb)
tail(GWAS.comb)
str(GWAS.comb)
# ******************************************************************************
# Write GWAS.output & GWAS.comb for future use.
# *Note this function can take a few minutes
save(GWAS.output, GWAS.comb, file = working.data.fname(5))
# on to script 6.Visualization
#___ end _______________________________________________________________________
# === Visualization ============================================================
# *Note 1.Main. R is required to run first to access folder paths and to input
# raw data required to run this script.
# All scripts must be run in numerical order
# Load data created in previous script, 5.Data.analysis.R
load(working.data.fname(5))
# Visualizing the results of the GWAS analysis.
# This script creates a Manhattan plot and a QQ plot from the analysed data.
# Plots are saved as pdfs to c.graphics folder.
# 1) Manhattan plot
# 2) Q-Q plot
# === 1) Manhattan plot ========================================================
# Manhattan plots are used to visualize GWA significance level by chromosome
# location. Visual inspection of this plot allows for identification of SNPs
# with relatively small p-values that are in regions with relatively large and
# non-significant p-values, suggesting potentially false findings. Association
# significance is established by p-values being above defined threshold such as
# the Bonferroni corrected threshold or the less stringent suggestive
# association threshold.
# we use a function created by Reed et. al (2015) to generate this plot.
# loading Manhattan Plot function
source("Manhattan.plot.R")
# creating Manhattan Plot and saving it as a .pdf
pdf(paste(p.graphics, "ManhattanPlot.pdf", sep = ""))
par(mfrow = c(1,1))
manhattan.plot.s <- GWAS.manhattan(GWAS.comb)
dev.off()
# === 2) Q-Q plot ===============================================================
# Q-Q plots are used to visualize the relationship between the expected
# and observed distributions of SNP-level test statistics. We use the function
# estlambda from the package GenABEL to generate our QQ plots.
# creating QQ Plot and saving it as a .pdf
pdf(paste(p.graphics, "qq.plot.pdf", sep = ""))
lambda.plot.s <- estlambda(GWAS.output$t.value^2, plot = TRUE,
method = "median")
dev.off()
#___ end _______________________________________________________________________
pdf(paste(p.graphics, "pc.plot.pdf", sep = ""))
pc.plot <- plot(pctab$PC2, pctab$PC1, xlab = "Principal Component 2",
ylab = "Principal Component 1", main = "Ancestry Plot")
dev.off()
